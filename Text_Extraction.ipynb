{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Saumya-dash/GenAI-Newsletter-Codes/blob/main/Text_Extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BA149dhH4IOq",
        "outputId": "2f4b9676-e2be-499b-87f0-b5b4a55cba9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-oruvd_kj\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-oruvd_kj\n",
            "  Resolved https://github.com/openai/whisper.git to commit b91c907694f96a3fb9da03d4bbdc83fbcd3a40a4\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20230314) (2.0.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20230314) (0.56.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20230314) (1.22.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20230314) (2.0.1+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20230314) (4.65.0)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20230314) (9.1.0)\n",
            "Requirement already satisfied: tiktoken==0.3.3 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20230314) (0.3.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.3.3->openai-whisper==20230314) (2022.10.31)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.3.3->openai-whisper==20230314) (2.27.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper==20230314) (3.25.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper==20230314) (3.12.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper==20230314) (16.0.6)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20230314) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20230314) (67.7.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20230314) (4.6.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20230314) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20230314) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20230314) (3.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper==20230314) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper==20230314) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper==20230314) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper==20230314) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20230314) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper==20230314) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/openai/whisper.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNhdGBNd0lv7",
        "outputId": "b9b3bf94-71ac-40a0-8ccd-d93846f872c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting python-docx\n",
            "  Downloading python-docx-0.8.11.tar.gz (5.6 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/5.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.3/5.6 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/5.6 MB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m66.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: lxml>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.9.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2022.7.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.22.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Building wheels for collected packages: python-docx\n",
            "  Building wheel for python-docx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-docx: filename=python_docx-0.8.11-py3-none-any.whl size=184491 sha256=bc2f5d76817fbe1205e8177de9e098198933d590a524a61aec84bcc86d957c4d\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/27/06/837436d4c3bd989b957a91679966f207bfd71d358d63a8194d\n",
            "Successfully built python-docx\n",
            "Installing collected packages: python-docx, PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1 python-docx-0.8.11\n"
          ]
        }
      ],
      "source": [
        "!pip install python-docx PyPDF2 pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5EJZmoCR70s1",
        "outputId": "42c5da69-65c4-4fcb-ee09-4f0cba518d38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.2.7-0ubuntu0.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 15 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!apt-get install ffmpeg -y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWnQxy0t2MIr",
        "outputId": "a3e9fd2b-83fa-4f10-f863-a7dd8ea3410c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing new file: WEF_Global_Risks_Report_2023.pdf\n",
            "Processing new file: Complete-set-guidelines.pdf\n",
            "Processing new file: whisper.pdf\n",
            "Processing new file: SaveTube.io - Game of Thrones Season 4_ Episode #6 Clip - Tyrion's Breakdown (HBO) (128 kbps).mp3\n",
            "Processing new file: news.pdf\n",
            "Final Output:\n",
            "                      WEF_Global_Risks_Report_2023.pdf  \\\n",
            "0    The Global Risks Report 2023 18th Edition INSI...   \n",
            "1    platform are available at https://www.weforum....   \n",
            "2    to 2025 Cost-of-living crisis Economic downtur...   \n",
            "3    Notes: Global Risks Perception Survey 2022-202...   \n",
            "4    that a divergent economic recovery from the CO...   \n",
            "..                                                 ...   \n",
            "471  Myers (US International Development Finance Co...   \n",
            "472  (Education International), Bridget Fawcett (Ci...   \n",
            "473  colleagues who contributed to our thematic con...   \n",
            "474  help in review: Sean de Cleene, Daniel Dobrygo...   \n",
            "475  Switzerland Tel.: +41 (0) 22 869 1212 Fax: +41...   \n",
            "\n",
            "                           Complete-set-guidelines.pdf  \\\n",
            "0    Guidelines for SWACHH BHARAT MISSION GRAMIN (R...   \n",
            "1    Micro Financing of Construction of Toilets 20 ...   \n",
            "2    GOVERNMENTAL ORGANISATIONS/SELF HELP GROUPS/SU...   \n",
            "3    Accounts for the Period 1st April, 201* to 31s...   \n",
            "4    be declared ODF 50 VI Modification in Funding ...   \n",
            "..                                                 ...   \n",
            "471                                                NaN   \n",
            "472                                                NaN   \n",
            "473                                                NaN   \n",
            "474                                                NaN   \n",
            "475                                                NaN   \n",
            "\n",
            "                                           whisper.pdf  \\\n",
            "0    Robust Speech Recognition via Large-Scale Weak...   \n",
            "1    as a foundation for further work on robust spe...   \n",
            "2    of the art, especially in a low-data setting. ...   \n",
            "3    <jongwook@openai.com >. 1Baevski et al. (2021)...   \n",
            "4    objects on seven other natural image datasets....   \n",
            "..                                                 ...   \n",
            "471                                                NaN   \n",
            "472                                                NaN   \n",
            "473                                                NaN   \n",
            "474                                                NaN   \n",
            "475                                                NaN   \n",
            "\n",
            "    SaveTube.io - Game of Thrones Season 4_ Episode #6 Clip - Tyrion's Breakdown (HBO) (128 kbps).mp3  \\\n",
            "0    Father, I wish to confess. I wish to confess. ...                                                  \n",
            "1    nothing to say in your defense? Nothing but th...                                                  \n",
            "2    here, so I will let the gods decide my fate. I...                                                  \n",
            "3                                                  NaN                                                  \n",
            "4                                                  NaN                                                  \n",
            "..                                                 ...                                                  \n",
            "471                                                NaN                                                  \n",
            "472                                                NaN                                                  \n",
            "473                                                NaN                                                  \n",
            "474                                                NaN                                                  \n",
            "475                                                NaN                                                  \n",
            "\n",
            "                                              news.pdf  \n",
            "0    1 Maha Mumbai Metro- Branding Vision and Style...  \n",
            "1    a brand design and style guidelines to be foll...  \n",
            "2    commitment to the citizens in overcoming the i...  \n",
            "3    “ Follow the Line The Brand design, Style guid...  \n",
            "4    Mission, Values and Approach . Taking the read...  \n",
            "..                                                 ...  \n",
            "471                                                NaN  \n",
            "472                                                NaN  \n",
            "473                                                NaN  \n",
            "474                                                NaN  \n",
            "475                                                NaN  \n",
            "\n",
            "[476 rows x 5 columns]\n",
            "Final output saved as /content/drive/MyDrive/Extraction_/Output/final_output.csv\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import docx\n",
        "from docx import Document\n",
        "import PyPDF2\n",
        "import whisper\n",
        "import pandas as pd\n",
        "from moviepy.editor import VideoFileClip\n",
        "\n",
        "def extract_text_from_pdf(file_path):\n",
        "    with open(file_path, 'rb') as file:\n",
        "        pdf_reader = PyPDF2.PdfReader(file)\n",
        "        text = ''\n",
        "        for page in pdf_reader.pages:\n",
        "            text += page.extract_text()\n",
        "        return text\n",
        "\n",
        "def extract_text_from_doc(file_path):\n",
        "    doc = docx.Document(file_path)\n",
        "    contents = \"\"\n",
        "    for paragraph in doc.paragraphs:\n",
        "        contents += paragraph.text\n",
        "    return contents\n",
        "\n",
        "def extract_text_from_docx(file_path):\n",
        "    doc = Document(file_path)\n",
        "    paragraphs = [p.text for p in doc.paragraphs]\n",
        "    return '\\n'.join(paragraphs)\n",
        "\n",
        "def extract_text_from_audio(file_path):\n",
        "    model = whisper.load_model(\"medium\")\n",
        "    result = model.transcribe(file_path)\n",
        "    return result[\"text\"]\n",
        "\n",
        "def convert_video_to_audio(video_path, audio_path):\n",
        "    video = VideoFileClip(video_path)\n",
        "    audio = video.audio\n",
        "    audio.write_audiofile(audio_path)\n",
        "\n",
        "def extract_text_from_file(file_path):\n",
        "    if file_path.endswith('.pdf'):\n",
        "        return extract_text_from_pdf(file_path)\n",
        "    elif file_path.endswith('.docx'):\n",
        "        return extract_text_from_docx(file_path)\n",
        "    elif file_path.endswith('.doc'):\n",
        "        return extract_text_from_doc(file_path)\n",
        "    elif file_path.endswith('.mp3'):\n",
        "      return extract_text_from_audio(file_path)\n",
        "    elif file_path.endswith('.mp4'):\n",
        "      convert_video_to_audio(file_path, '\\\\content\\\\drive\\\\MyDrive\\\\Extraction_\\\\converted_audios\\\\new_audio.mp3')\n",
        "      return extract_text_from_audio('\\\\content\\\\drive\\\\MyDrive\\\\Extraction_\\\\converted_audios\\\\new_audio.mp3')\n",
        "    else:\n",
        "        None\n",
        "\n",
        "def tokenize_text(text, max_tokens=100):\n",
        "    tokens = []\n",
        "    words = text.split()\n",
        "    for i in range(0, len(words), max_tokens):\n",
        "        tokens.append(' '.join(words[i:i+max_tokens]))\n",
        "    return tokens\n",
        "\n",
        "def process_new_files(folder_path, processed_files, data):\n",
        "    new_files = set(os.listdir(folder_path)) - processed_files\n",
        "    for file_name in new_files:\n",
        "        file_path = os.path.join(folder_path, file_name)\n",
        "        if os.path.isfile(file_path):\n",
        "            print(f\"Processing new file: {file_name}\")\n",
        "            text = extract_text_from_file(file_path)\n",
        "            tokens = tokenize_text(text)\n",
        "            data[file_name] = pd.Series(tokens)\n",
        "            processed_files.add(file_name)\n",
        "\n",
        "def monitor_folder(folder_path, output_folder):\n",
        "    processed_files = set()\n",
        "    data = pd.DataFrame()\n",
        "    while True:\n",
        "        process_new_files(folder_path, processed_files, data)\n",
        "        if len(processed_files) > 0:\n",
        "            print(\"Final Output:\")\n",
        "            print(data)\n",
        "            output_file_path = os.path.join(output_folder, \"final_output.csv\")\n",
        "            data.to_csv(output_file_path, index=False)\n",
        "            print(f\"Final output saved as {output_file_path}\")\n",
        "            break\n",
        "\n",
        "folder_path = '/content/drive/MyDrive/Extraction_/Files'  # Specify the folder path in Colab's environment\n",
        "output_folder = '/content/drive/MyDrive/Extraction_/Output'  # Specify the desired output folder path\n",
        "monitor_folder(folder_path, output_folder)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "j7wnbxpHFxhE",
        "outputId": "09f0c8f9-8345-4cec-db3d-95b5e85c2e38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.10/dist-packages (1.0.3)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.65.0)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.27.1)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.1.10)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from moviepy) (1.22.4)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.25.1)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.4.8)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio<3.0,>=2.5->moviepy) (8.4.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install moviepy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Yc87nsrU8J52"
      },
      "outputs": [],
      "source": [
        "import whisper\n",
        "import moviepy.editor as mp\n",
        "\n",
        "from moviepy.editor import VideoFileClip\n",
        "\n",
        "def convert_video_to_audio(video_path, audio_path):\n",
        "    video = VideoFileClip(video_path)\n",
        "    audio = video.audio\n",
        "    audio.write_audiofile(audio_path)\n",
        "\n",
        "# Example usage\n",
        "video_file_path = '/content/drive/MyDrive/SaveTube.io-the godfather best scene-(480p).mp4'  # Replace with the actual path to your video file\n",
        "audio_file_path = '\\\\content\\\\drive\\\\new.mp3'  # Replace with the desired output audio file path\n",
        "convert_video_to_audio(video_file_path, audio_file_path)\n",
        "\n",
        "def extract_text_from_audio(file_path):\n",
        "    model = whisper.load_model(\"medium\")\n",
        "    result = model.transcribe(file_path)\n",
        "    return result[\"text\"]\n",
        "\n",
        "print(extract_text_from_audio(audio_file_path))\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}